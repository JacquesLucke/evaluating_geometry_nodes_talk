<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <title>Evaluating Geometry Nodes</title>

    <link rel="stylesheet" href="dist/reset.css" />
    <link rel="stylesheet" href="dist/reveal.css" />
    <link rel="stylesheet" href="dist/theme/black.css" />

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="plugin/highlight/my_theme.css" />

    <script src="https://js.polli.live/main.js"></script>

    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/d3/7.9.0/d3.min.js"
      integrity="sha512-vc58qvvBdrDR4etbxMdlTt4GBQk1qjvyORR2nrsPsFPyrs+/u5c3+1Ct6upOgdZoIl7eq6k3a1UPDSNAQi/32A=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/plotly.js/2.35.0/plotly.min.js"
      integrity="sha512-L205fVN73b8Ft9dbuwTVGFb4FHVSOPpCLMQzcHa4r0+CuUswxzK/JRW7glZrpC+bO3Yaka0DYYDmtlhVbmnX+g=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>

    <style>
      .reveal h1,
      .reveal h2,
      .reveal h3,
      .reveal h4,
      .reveal h5,
      .reveal h6 {
        text-transform: none;
      }

      .function-name {
        color: rgb(219, 166, 103);
      }

      .fragment.blur {
        filter: blur(0.2em);
      }

      .fragment.blur.visible {
        filter: none;
      }

      .filter-lazy-function-graph-svg {
        filter: invert(90%);
      }
    </style>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section><h2>Evaluating Geometry Nodes</h2></section>
        <section>
          <div
            style="display: grid; grid-template-columns: 2fr 3fr; height: 100%"
          >
            <div>
              <img
                class="polli-live-qr-code"
                style="
                  image-rendering: pixelated;
                  margin: 0;
                  width: 100%;
                  background-color: white;
                  border: 0.5em solid transparent;
                  border-radius: 0.5em;
                  box-sizing: border-box;
                "
              />
            </div>
            <div>
              Join the interactive part!
              <div
                class="polli-live-choice"
                id="join-interactivity"
                style="width: 100%"
              >
                <option>I'm in</option>
                <option>Wait</option>
              </div>
            </div>
          </div>
        </section>
        <section>
          <h2>Topics</h2>
          <p>Get Started</p>
          <p>Lazy Evaluation</p>
          <p>Array Processing</p>
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * Start with showing some simpler evaluation methods to set the scene.
              * These are also methods that make sense when just starting out to build a new node system.
            * Then we have a look at how the geometry nodes graph is processed and how it is evaluated at a high level.
            * Lastly, we have a look at how math functions are evaluated as part of field evaluation
          </aside>
        </section>
        <section>
          <h2>About Me</h2>
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * Started building node systems for Blender about 10 years ago when I was still in school (Animation Nodes).
            * Hired by Blender after my studies in 2018 and am working remotely from the Berlin area nowadays.
            * Lead developer for geometry nodes since the beginning in 2020.
            * Best thing about the job is seeing all the cool stuff people make with the tools Hans and I implement in our living rooms, with the help of many others of course.
              * I'm thankful for everyone who shares their early experiments especially when testing new features. It's super helpful and motivating.
          </aside>
        </section>
        <section>
          <h2>What's your background?</h2>
          <div class="polli-live-continuum" id="what-is-your-background-poll">
            <option>Artistic</option>
            <option>Both</option>
            <option>Technical</option>
          </div>
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * I'm also curious about the background of the audience.
            * Personally, I'm more on the technical side, but I'm always most impressed by people who combine technical and artistic skills.
              * Like Simon Thommes who is a great help in the geometry nodes team bridging the gap between the two worlds.
          </aside>
        </section>
        <section>
          <h2>Get Started</h2>
          <img src="images/get_started.png" />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * The image shows a simple node tree that I'll use as starting point to discuss some of the core concepts.
            * Using it I'll explain some simple graph evaluation strategies.
          </aside>
        </section>
        <section>
          <h2>Toposort</h2>
          <img src="images/toposort.png" />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * The simplest mechanims is to simply sort the nodes topologically.
              * That means that we order the nodes in a way that nodes always come after everything they depend on.
              * The ordering is always possible unless there are cycles in the node tree, but none of the other methods work in that case either.
            * Once sorted, we can just evaluate the nodes one after the other making sure we pass data correctly between them.
            * This general approach was used by Animation Nodes, with the addition that after sorting a Python script is generated that executes the nodes.
            * While very simple, this approach in its pure form has some significant limitations like:
              * All nodes are always evaluated, even if they are not needed.
              * It's hard to parallelize the evaluation.
            * While just using toposort is not great for evaluation, it's still a very important concept that's used in many places in Blender when analysing node trees.
          </aside>
        </section>
        <section>
          <h2>Two-Pass Evaluation</h2>
          <img src="images/two_pass.png" />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * A way to remedy the first problem is to process nodes in two passes.
              * In the first pass, we figure out which nodes are needed for the final result.
              * In the second pass, we only evaluate the nodes that are needed.
            * In the example here that means that we detect that the second Add node is not needed and it can be ignored.
            * In this case it's obvious because the output of the node is not used at all.
            * However, some more complex cases can be handled with this approach too.
              * The dependency graph evaluation uses a separate pass to first determine when objects are visible in the case of animated visibility.
              * Switch nodes with simple conditions could be handled this way too.
          </aside>
        </section>
        <section>
          <h2>Push vs. Pull</h2>
          <img src="images/switch_domain_size.png" />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * So far we've only looked at what I'd call push based evaluation.
              * That means that we first determine all nodes to evaluate and then start evaluating them at the beginning.
            * That can be good enough for many kinds of node systems.
              * It's used by shader (eevee and cycles) and compositor evaluation.
            * It's far from ideal for geometry nodes:
              * The problem is that we just can't determine which nodes have to be evaluated before having evaluated potentially large parts of the node tree already.
              * Also, the condition of switch nodes may depend on the result of other switch nodes.
              * Users have to be able to trust that when a switch node disables part of the node tree, that those nodes really won't be evaluated.
            * A solution is to use what I call a pull based evaluation system.
              * No preprocessing is necessary to determine which nodes are necessary.
              * That means, the evaluation does not start at the input, but at the output.
              * When a node is evaluated, it first requests the missing inputs from the nodes that come before.
              * Importantly, it does not have to request all of them at the same time.
                * For example, the switch node first only requests the condition input.
                * Once that comes back, it can request one of the remaining inputs.
            * This can be implemented relatively easily with a recursive evaluator.
              * Was done for the first geometry nodes evaluator.
              * Has significant limitations:
                * Single threaded
                * Long chains of nodes result in a long call stack which can lead to a stack overflow with just a few hundred nodes.
            * Solving this generically comes with some extra complexity, especially if multi-threaded evaluation has to be supported too.
            * Next I'll present the internal evaluation system we actually use for geometry nodes.
          </aside>
        </section>
        <section>
          <h2>Lazy Functions</h2>
          <ul style="list-style-type: none">
            <li><code class="function-name">get_or_request_input</code></li>
            <li><code class="function-name">set_output</code></li>
            <li>
              <code
                class="function-name fragment custom blur"
                data-fragment-index="1"
                >get_output_usage</code
              >
            </li>
            <li>
              <code
                class="function-name fragment custom blur"
                data-fragment-index="1"
                >set_input_unused</code
              >
            </li>
          </ul>
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * At the core of our lazy evaluation system is the `LazyFunction` class.
            * All nodes are implemented as lazy-function in Geometry Nodes.
              * That may not be immediately obvious when working on nodes though.
              * That's because most nodes use a more high-level API that hides away the lazyness aspect.
              * More special nodes like the different kinds of Switch nodes are implemented directly as `LazyFunction` though.
            * A lazy function uses the following methods to interact with its inputs and outputs...
            * The lazy-function API is independent of geometry nodes, so it can also be tested independently.
          </aside>
        </section>
        <section>
          <h2>Lazy Function Graph</h2>
          <img
            src="images/simple_lazy_function_graph.svg"
            class="filter-lazy-function-graph-svg"
          />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * Each geometry node tree is first converted into a lazy function graph like the one shown here.
            * It's typically very similar to the corresponding node tree with some differences:
              * It has some extra stuff that's needed to handle the lifetimes of anonymous attributes.
                * See the "Usage" and "Propagate" sockets.
              * Zones are also represented differently in the graph.
            * The geometry nodes modifier or node tools operator then takes this generated lazy-function graph and evaluates it.
            * For that it provides all the inputs and requests all the main outputs.
            * It's a limitation that the modifier always has to provide all inputs, but lazyness is not possible outside of the modifier yet.
            * For debugging purposes, this graph can be visualized using a Core Debug Tools add-on that can be installed via the extensions platform.
          </aside>
        </section>
        <section>
          <h2>Message Passing</h2>
          <img
            src="images/lazy_function_with_named_links.svg"
            class="filter-lazy-function-graph-svg"
          />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            1. Request geometry from subdivide node.
            2. Request Mesh and Propagate inputs.
            3. Switch node requests condition input.
            4. Once that is ready, the switch node is evaluated again, this time it requests the False input and sets the True input as unused.
            5. Once that is ready, it simply forwards the geometry to the subdivide node.
            6. It performs subdivision and forwards the result to the output.
          </aside>
        </section>
        <section>
          <h2>Scheduling - Message Priority</h2>
          <img src="images/message_priority.png" />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * The order in which the messages are processed it not important for correctness.
            * However, it can have a significant impact on performance.
            * In this case we'd expect that we never have to make a copy of the cube mesh.
            * A copy could happen though if the condition is True.
              * In that case, the cube mesh is forwarded to the Set Position node and Switch node.
              * Internally there are now two references to the cube mesh.
              * So when the Set Position node wants to modify it, it first has to make a copy to avoid changing the other one.
            * This is solved by giving the messages that specify that a certain input is not required higher priority.
              * Then we know that the False input of the switch node is not needed and the Set Position node is the sole owner of the mesh.
            * This used to be a relatively large problem, but it's a bit better now since we make extensive use of implicit sharing on geometry data structures.
              * That means that when a geometry is copied, we rarely have to copy large arrays, but only increase their references counts.
          </aside>
        </section>
        <section>
          <h3>Scheduling - Breadth vs. Depth First</h3>
          <img src="images/breadth_vs_depth_first.png" />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * Messages may schedule nodes. Now the question is which node to evaluate next when multiple nodes are scheduled.
            * There are two main strategies:
              * In breadth first scheduling, we evaluate nodes in the order in which they got scheduled.
                * So after the Join Geometry node is scheduled, all three Bounding Box nodes are evaluated, which then schedule the three primitive nodes.
                * Only after all three primitive nodes have been executed, the bounding box nodes are evaluated.
              * In depth first scheduling, we always evaluate the node that was last scheduled next.
                * So after the first bounding box node, the corresponding primitive node is evaluted which schedules the bounding box node again.
                * Then the bounding box node is evaluated before the next node is run.
          </aside>
        </section>
        <section>
          <h2>Breadth or Depth First?</h2>
          <div
            class="polli-live-choice"
            id="breadth-vs-depth-first"
            data-hide-answer
          >
            <option>Depth First</option>
            <option>Breadth First</option>
          </div>
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * What do you think is the better main strategy?
            * Breadth first turns out to work better usually, because it leads to a lower peak memory usage.
            * Also it makes it more likely that the next evaluated node works on the same data that the previous node just created.
              * This improves cache utilization.
          </aside>
        </section>
        <section>
          <h2>Lazy Function Composition</h2>
          <p>
            <code class="function-name">LazyFunction</code> &#10230;
            <code class="function-name">Graph</code> &#10230;
            <code class="function-name">LazyFunction</code>
          </p>
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * We have a already seen that multiple lazy functions can be combined in a graph.
            * An important and powerful design aspect is that it is possible to wrap the entire graph in a new lazy function.
            * This new function can then be used as a single node in a new graph and behaves pretty much exactly the same as if all the nodes were inlined.
            * This is quite powerful, because it allows building many smaller graphs which can be combined in a bigger one without loosing any of the lazyness.
            * We make extensive use of that for node groups and zones.
          </aside>
        </section>
        <section>
          <h2>Node Groups</h2>
          <img
            src="images/node_group.svg"
            class="filter-lazy-function-graph-svg"
          />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * There are two main ways to handle node groups during node evaluation.
            * One can inline all nodes into a single node tree or one can keep them separate.
            * Always inlining has the benefit that it can be done in a preprocessing step and the code afterwards does not have to worry about it anymore.
              * Specifically, the lazy function graph evaluator would not have to be able to handle nested functions.
              * Furthermore, some optimizations may be easier to implement on a flat graph instead of a nested one.
            * All node systems except geometry nodes flatten the entire node tree before evaluation currently.
            * Geometry nodes does not inline node groups because:
              * The evaluator would have to be able to handle nesting anyway because of zones.
              * Geometry nodes trees tend to get much bigger than in other node systems.
                * Having more than ten thousand nodes after everything is inlined is not uncommon.
                * It's quite expensive to inline all of that.
                * Especially, considering that often only a much smaller part is actually evaluated and the rest is disabled by switch nodes when using high level assets.
              * Currently, we don't have the need to implement optimizations that would require inlining, but if that's really necessary, we can still selectively inline some node groups.
          </aside>
        </section>
        <section>
          <h2>Zones</h2>
          <img
            src="images/repeat_zone.svg"
            class="filter-lazy-function-graph-svg"
          />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * When the geometry nodes tree is converted into a lazy-function graph, each zone becomes a single node.
            * A separate graph is created for each zone.
            * What kind of graph is created depends on the type of zone.
            * The Repeat and For Each zone dynamically create a graph that based on the number of iterations.
            * The shown graph is for a repeat zone with 3 iterations. Note how there are 3 instances of the Repeat Body node which is yet another graph that contains all nodes inside the zone.
            * This approach has the significant advantage that the existing graph evaluator can be used to evaluate these zones without any extra complexity.
            * Using the existing evaluator also means that we get all the scheduling and multi-threading optimizations of it for free.
              * For example, it's perfectly possible that nodes in multiple repeat iterations are evaluated at the same time.
            * This approach is not ideal for cases where the work done in the zone body is very cheap.
              * In the future we could try to detect such cases and evaluate such zones in a different way that is faster but does not support lazyness to the same degree.
          </aside>
        </section>
        <section>
          <h2>Scheduling - Multi Threading</h2>
          <img src="images/multi_threading_simple.png" />
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * In many cases it is possible to evaluate nodes in parallel.
            * The message passing architecture of the evaluator makes it fairly straight to implement basic multi-threading.
            * Nodes that are scheduled can be evaluated in parallel.
            * Each node has a mutex that can be locked when sending a message to it.
            * Internally that uses a task group provided by the TBB library.
          </aside>
        </section>
        <section>
          <h2>Task Stealing</h2>
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * Task stealing is the strategy used to distribute work between threads in the TBB library.
            * It roughly works like so:
              * Each thread has its own queue of tasks to execute.
              * When a thread runs out of tasks, it randomly picks another thread and steals half of its tasks.
              * After a short while, each thread will have work assuming there is enough work.
            * This is different from e.g. explicitly assigning tasks to threads and has some nice performance and scaling benefits.
          </aside>
        </section>
        <section>
          <h2>Multi Threading Overhead</h2>
          <pre class="cpp"><code data-trim>
            parallel_for(10'000, 512, [&](const IndexRange range) {
              ...
            });
          </code></pre>
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * There is one big issue with the approach I described so far and that is that each communication across threads and each lock comes at a cost.
            * This cost can be much higher than the actual work done by the nodes, especially when there are many cheap nodes like math nodes.
            * Ideally, we'd like to detect situations when multi-threading is beneficial and only then use it.
            * This is not trivial, but lets first look at how that's done in simpler cases.
            * The shown example shows a common case where we want to process 10.000 elements in parallel.
            * We always specify the so called "grain size" which is the size of a unit of work.
            * If the total number of elements to process is smaller, all work is done on the current thread without any multi-threading overhead.
          </aside>
        </section>
        <section>
          <h2>Lazy Threading</h2>
          <p>
            <span class="function-name">Non-Uniform</span> and
            <span class="function-name">Unknown</span> Task Sizes
          </p>
          <!-- prettier-ignore -->
          <aside class="notes" data-markdown>
            * Unfortunately, the same approach does not work for graph evaluation because of two main reasons:
              * The tasks do not have a uniform size. That implies that a simple grain size does not work because that depends on the size.
              * Furthermore, we do not even know the task sizes in advance. Most nodes in geometry nodes can be cheap or expensive depending on the specific inputs.
            * The solution is to use an approach I call "lazy threading". That works as follows:
              * By default, the evaluator is single threaded, so no communication between threads and locks are necessary.
              * While a task is being executed, it may inform the scheduler that invoked it that it takes a while.
              * The scheduler can then decide to enable multi-threading and to move all tasks that are already scheduled to a task group that other threads can steal from.
              * After multi-threading is enabled in the scheduler, all messages that are passed around need locks.
              * However, note that all the nested node graphs are still evaluated in single-thread mode which typically contain the majority of nodes.
            * The main remaining question is when and how tasks send messages to the scheduler.
              * It works by letting the scheduler put a custom callback into thread-local storage that the tasks can call (with a simple API).
              * The when is more tricky because it would be annoying to add extra scheduler specific code in lots of places.
              * Fortunately, I noticed that we do have that code in many places already.
              * All the grain sizes we use for `parallel_for` already provide heuristics that can be reused here by just adding a little bit of extra code in `parallel_for`.
          </aside>
        </section>
      </div>
    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script>
      const standard_width = 960;
      const standard_height = 700;
      const graphs_container_ids = [];

      async function make_graph(
        source_file_path,
        container_id,
        x_name,
        y_name,
        filter_x_fn = (v) => true
      ) {
        const container_elem = document.getElementById(container_id);
        if (!container_elem) {
          console.error("Container not found:", container_id);
          return;
        }

        let csv_data = await d3.csv(
          "analysis/grain_size_results.csv",
          d3.autoType
        );
        csv_data = csv_data.filter((v) => filter_x_fn(v[x_name]));
        graphs_container_ids.push(container_id);

        container_elem.style.width = "100%";
        container_elem.style.aspectRatio = "2 / 1";
        container_elem.style.display = "flex";
        container_elem.style.justifyContent = "center";
        container_elem.style.alignItems = "center";

        const trace1 = {
          x: csv_data.map((v) => v[x_name]),
          y: csv_data.map((v) => v[y_name]),
          type: "lines+markers",
          line: {
            color: "rgb(219, 166, 103)",
          },
        };

        const data = [trace1];

        const tick_font_size = 36;
        const title_font_size = 24;

        const layout = {
          paper_bgcolor: "transparent",
          plot_bgcolor: "transparent",
          showlegend: false,
          xaxis: {
            gridcolor: "#222",
            tickcolor: "transparent",
            tickformat: ",.0f",
            nticks: 5,
            tickfont: {
              color: "white",
              size: tick_font_size,
            },
            title: {
              text: x_name,
              font: {
                size: title_font_size,
                color: "white",
              },
              standoff: 20,
            },
          },
          yaxis: {
            gridcolor: "#222",
            tickcolor: "transparent",
            tickformat: ",.0f",
            nticks: 5,
            tickfont: {
              color: "white",
              size: tick_font_size,
            },
            title: {
              text: y_name,
              font: {
                size: title_font_size,
                color: "white",
              },
              standoff: 10,
            },
          },
          margin: {
            l: 110,
            r: 110,
            b: 100,
            t: 0,
            pad: 0,
          },
          scrollZoom: false,
          dragmode: false,
        };

        Plotly.newPlot(container_id, data, layout, {
          displayModeBar: false,
          responsive: false,
        });
      }

      // make_graph(
      //   "analysis/grain_size_results.csv",
      //   "first-plot",
      //   "Grain Size",
      //   "Time (s)",
      //   (x) => x < 10000
      // );
      // make_graph(
      //   "analysis/grain_size_results.csv",
      //   "second-plot",
      //   "Grain Size",
      //   "Time (s)",
      //   (x) => true
      // );

      polli_live.initialize({
        width: standard_width,
        height: standard_height,
      });
      Reveal.initialize({
        hash: true,
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes],
      });
      Reveal.addEventListener("slidechanged", function (event) {
        const currentSlide = event.currentSlide;
        if (!currentSlide) {
          return;
        }
        for (const container_id of graphs_container_ids) {
          const element = currentSlide.querySelector("#" + container_id);
          if (element) {
            Plotly.Plots.resize(element);
          }
        }
      });
    </script>
  </body>
</html>
